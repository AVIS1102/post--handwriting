<!doctype html>
<meta charset="utf-8">
<meta name="viewport" content="width=768, initial-scale=1">
<script type="text/front-matter">
  title: Experiments in Handwriting with a Neural Network
  description: Several interactive visualizations of a generative model of handwriting. Some are fun, some are serious.
  authors:
    - Shan Carter: http://shancarter.com
    - David Ha: https://github.com/hardmaru
    - Ian Johnson: https://github.com/enjalot
    - Chris Olah: http://colah.github.io/
  affiliations:
    - Google Brain: http://g.co/brain
    - Google Brain: http://g.co/brain
    - Google Cloud: http://cloud.google.com
    - Google Brain: http://g.co/brain
</script>

<script src="assets/webcomponents-lite.min.js"></script>
<link rel="import" href="assets/polymer-mini.html">
<script src="assets/d3.min.js"></script>
<script src="assets/d3-scale-chromatic.min.js"></script>

<script>
  function cellClick(cell) {
    document.querySelector('figure-cells[mode=sorted]').setCell(cell);
  }
</script>

<link rel="import" href="assets/distill-stage-manager.html">
<link rel="import" href="assets/figure-animated.html">
<link rel="import" href="assets/figure-predict.html">
<link rel="import" href="assets/figure-hairs.html">
<link rel="import" href="assets/figure-cells.html">
<link rel="import" href="assets/figure-cells-draw.html">

<style>
.post h2 {
  border-bottom: none!important;
}
  .post .controls {
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    margin-top: 48px;
    padding-top: 18px;
  }
  .post .controls span {
    font-size: 14px;
  }
  .post .controls button {
    font-size: 13px;
    padding: 4px 8px;
    border-radius: 3px;
    background-color: rgba(0, 0, 0, 0.03);
    border: 1px solid rgba(0, 0, 0, 0.2);
  }
  .post .controls select {
    margin-right: 8px;
    font-size: 13px;
    font-family: "Open sans";
    border-radius: 3px;
    background-color: rgba(0, 0, 0, 0.03);
    border: 1px solid rgba(0, 0, 0, 0.2);
  }
  .post .controls input[type="range"] {
    position: relative;
    top: 3px;
  }
  .post sup {
    vertical-align: baseline;
    position: relative;
    top: -8px;
    margin: 0 3px 0 2px;
    font-size: 12px;
  }
  .post a {
    cursor: pointer;
  }

</style>

<dt-article class="centered post">
  <h1 class="l-middle">Four Experiments in Handwriting with a Neural Network</h1>
  <h2 class="l-middle">Let’s start with generating new strokes based on your handwriting input</h2>

  <div class="l-screen" style="position: relative;">
    <div style="position: absolute; width: 100%;">
      <div class="controls l-page" id="figure-predict-controls" style="z-index: 10;position: relative;margin-top: 18px;">
        <button onclick="document.querySelector('figure-predict').playToggle()">Play/Pause</button>
        <button onclick="document.querySelector('figure-predict').clear()">Clear</button>

        <span style="margin-left: 18px;">Length of prediction</span>
        <input type="range" value="20" min="5" max="200" step="5" oninput="document.querySelector('figure-predict').setPredictionLength(this.value); document.querySelector('#figure-predict-controls .prediction-length').textContent = this.value;" style="width: 70px;"/>
        <span class="prediction-length" style="display: inline-block; width: 18px; text-align: left; margin-left: 6px;">20</span>

        <span style="margin-left: 18px;">Variation<dt-fn>The model has a parameter which determines how widely it samples from the underlying distribution. It is labeled here as variation but is more commonly referred to as temperature. Temperature is most commonly discussed in <a href="https://en.wikipedia.org/wiki/Boltzmann_distribution">Boltzmann distributions</a>, but can be generalized to all probability distributions. In this more general form, changing the temperature by a factor of <i>T</i> corresponds to raising all probabilities to the power of <i>1/T</i> and normalizing.</dt-fn></span>
        <input type="range" value="0.1" min="0.1" max="0.7" step="0.05" oninput="document.querySelector('figure-predict').setTemperature(this.value); document.querySelector('#figure-predict-controls .temperature').textContent = this.value;" style="width: 70px;"/>
        <span class="temperature" style="display: inline-block; width: 40px;">0.1</span>

      </div>
    </div>
    <figure-predict class="l-screen" temperature="0.1" predictionlength="20"></figure-predict>
  </div>

  <dt-byline></dt-byline>

  <p> Neural networks are an extremely successful approach to machine learning, but it’s tricky to understand why they behave the way they do. This has sparked a lot of interest and effort around trying to understand and visualize them, which we think is so far just scratching the surface of what is possible.</p>

  <p>In this article we will try to push forward in this direction by taking a generative model of handwriting<dt-fn>The model used in this articles is a version of the model described in Section 4.2 of <a href="https://arxiv.org/abs/1308.0850">Generating Sequences With Recurrent Neural Network</a> by Alex Graves <dt-cite key="graves2013generating"></dt-cite>. It is a small LSTM, with 500 hidden units, trained to perform the unconditional handwriting generation task.  For a detailed description of the model and training procedure, please refer to <a href="http://blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow/">this blog post</a> <dt-cite key="ha2016handwriting"></dt-cite> in addition to the Graves paper.  After training the LSTM, we quantized the weights using 8-bit integers, and exported the weights into a small <a href="https://jb64.org/specification/">JSON-Base64</a> formatted file.</dt-fn> and visualizing it in a number of ways.  The model is quite simple (so as to run well in the browser) so the generated output mostly produces gibberish letters and words (albeit, gibberish that look like real handwriting), but it is still useful for our purposes of exploring visualization techniques.</p>

  <p>In the end we don’t have some ultimate answer or visualization, but we do have some interesting ideas to share. Ultimately we hope they make it easier to divine some meaning from the internals of these model.</p>

  <h2>Looking at the Output of the Model</h2>

  <p>Our first experiment is the most obvious: when we want to see how well someone has learned a task we usually ask them to demonstrate it. So, let’s ask our model to write something for us and see how well it does.</p>

  <div class="controls l-body" id="figure-animated-controls">
    <button class="play" onclick="document.querySelector('figure-animated').togglePlay()">Play/Pause</button>
    <span style="margin-left: 8px;">Variation<sup><a href="#footnote1">1</a></sup></span>
    <input type="range" value="0.6" min="0.1" max="1.5" step="0.05" oninput="document.querySelector('figure-animated').temperature(this.value); document.querySelector('#figure-animated-controls .value').textContent = this.value;" />
    <span class="value">0.6</span>
  </div>
  <figure-animated class="l-page" temperature="0.6"></figure-animated>

  <p>Most of the marks are gibberish, but many of them are surprisingly convincing. Some real (or real-ish) words even start to appear. One surprising thing you’ll notice is that the general style of handwriting is more or less consistent within a sample. This is because the type of architecture used for this model (LSTM) has a mechanism for remembering previous strokes. It is therefore able to remember things like how loopy or jerky the handwriting is, or which letter preceeded the current one. (For more on LSTMs and how they can remember, Chris Olah has a <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">good primer</a> <dt-cite key="olah2015understanding"></dt-cite>.)</p>

  <p>Even with this memory, the technique for generating samples from neural networks is probabilistic, meaning each of these samples is one of a much, much larger possibility space. Viewing them one at a time feels unsatisfying — how can we infer much from one or two samples when there are nearly infinite possibilities? If something looks wrong, how do we know if it was because there is something fundamentally wrong with our model or if it was just dumb luck?</p>

  <figure class="l-gutter">
    <img class="key" src="assets/color-key.svg" style="width: 145px;">
  </figure>

  <p>At each iteration our model could have produced many paths. Instead of picking one and throwing the rest away, let’s draw, say, 50 of them. Green strokes below are places where the model would have veered rightward from the chosen stroke, orange is where it would have veered leftward.</p>

  <figure-hairs class="l-screen">
    <div class="controls l-body">
      <select class="sample">
        <option value="001">Generated sample 1</option>
        <option value="002">Generated sample 2</option>
        <option value="003" selected>Generated sample 3</option>
        <option value="004">Generated sample 4</option>
        <option value="005">Generated sample 5</option>
        <option value="straight">Straight line</option>
      </select>

      <span style="margin-left: 18px;">Steps</span>
      <input type="range" min="0" max="2" step="1" class="step" value="2" style="width: 80px;"></input>
      <span class="value">4</span>

      <span style="margin-left: 18px;">Variation<sup><a href="#footnote1">1</a></sup></span>
      <input type="range" min="0" max="2" step="1" class="temperature" value="1" style="width: 80px;"></input>
      <span class="temperature-val">0.5</span>
    </div>
  </figure-hairs>

  <p>With this technique we are casting a light into a wider possibility space. You can see some areas where there was general consensus as to what to do next. Other areas had more of a “anything can happen next” feeling. Others seem to show a possible fork in the road. “We can be drawing an “a” or “g”. A few steps later it’s clear the model has converged on a cursive “g”.</p>

  <figure class="l-gutter">
    <img class="key" src="assets/color-key.svg" style="width: 145px;">
  </figure>

  <p>In addition to visualizing samples generated by the model, this technique can also be applied to human-generated samples. Below we can see what the model would have done at each point if it had taken over for the person.</p>

  <figure-hairs class="l-screen">
    <div class="controls l-body">
      <select class="sample">
        <option value="0">Validation sample 0</option>
        <option value="1">Validation sample 1</option>
        <option value="2" selected>Validation sample 2</option>
        <option value="3">Validation sample 3</option>
        <option value="4">Validation sample 4</option>
        <option value="v7">Validation sample 5</option>
        <option value="v5">Validation sample 6</option>
      </select>

      <span style="margin-left: 18px;">Steps</span>
      <input type="range" min="0" max="2" step="1" class="step" value="2" style="width: 80px;"></input>
      <span class="value">4</span>

      <span style="margin-left: 18px;">Variation<sup><a href="#footnote1">1</a></sup></span>
      <input type="range" min="0" max="2" step="1" class="temperature" value="1" style="width: 80px;"></input>
      <span class="temperature-val">0.5</span>
    </div>
  </figure-hairs>

  <p>It is obvious from these experiments that this model has learned quite a lot about human handwriting. Which sort of raises the question, can we extract that knowledge in any meaningful way, rather than just blindly using it to mimic handwriting?</p>

  <h2>Examining the Internals of the Model</h2>

  <p>Our model has 500 cells which act as a sort of memory which it will use as part of its input when deciding what to generate. If we can see what those cells are doing as the model progresses we may be able to gain some intuitive understanding about what the model is doing.</p>

  <p>We begin by showing the activation of the cells over time. Each column in the heatmap below represents one line segment of the handwriting. Each row represents one cell of the model and is colored by its activations on that part of the stroke. By inspecting the diagram you may be able to see some patterns in the way certain cells activate for certain types of strokes. You can change which cell is used to color the strokes by clicking on the diagram.</p>

  <figure-cells class="l-page" mode="unsorted" defaults="93,0"></figure-cells>

  <p>You may have been able to pick out one or two cells with interesting patterns, but we have reason to believe that cells work in tandem, such that an individual cell’s activity may not be as interesting as a group of cells.</p>

  <p>Is there a way to order the cells to make this structure clearer? We've found that applying one-dimensional <a href="https://lvdmaaten.github.io/tsne/">t-SNE</a> <dt-cite key="maaten2008visualizing"></dt-cite> to the activations of the cells over time can organize them, bringing cells with similar behavior close together. This makes the diagram easier to read. We use a few small tricks to achieve the best results.<dt-fn> We use two different tricks to make the t-SNE organization of neurons work better. First, if a cell state is mostly negative, we canonicalize it by flipping its sign. (From the LSTM's perspective, this is completely equivelant, provided we flip the sign of some weights. The sign of a cell state is arbitrary.) Secondly, we tried using different metrics on points in our dataset for t-SNE, encouraging it to put points we think of as similar close together. We got good results basing our metric on blurred data (so that cells offset forward or backwards by one are still close together) and a blurred <a href="https://en.wikipedia.org/wiki/Sobolev_space">Sobolev metric</a> to encourage sharp changes to line up. We achieved slightly better results, presented in the article, yet by creating a metric based on percentiles of cell activation in a neighborhood. See `bin/sort` in the repository for details.</dt-fn></p>

  <figure-cells class="l-page" mode="sorted" defaults="55,0"></figure-cells>

  <p>In this version we can find a few clear behaviors. For example, cells <a onclick="cellClick(11)">11</a>-<a onclick="cellClick(70)">70</a> at the top seem sensitive to slightly different directions and curvatures of the pen path -- see in particular cells <a onclick="cellClick(25)">25</a> and <a onclick="cellClick(55)">55</a>. On the other hand, at the bottom, cells below <a onclick="cellClick(427)">427</a> seem focused on pen lifts; for example, cell <a onclick="cellClick(494)">494</a> seems to predict whether the pen is about to be lifted. In the middle, we see a variety of cells, including some tracking absolute position. Cell <a onclick="cellClick(136)">136</a> and its neighbors seem concerned with horizontal position, while cells around <a onclick="cellClick(236)">236</a> seem concerned with vertical position. Cell <a onclick="cellClick(242)">242</a> appears to track position within a word. </p>

  <p>Another way to explore the activations is to give it a sample and interactively see the activations. Below you can write and see the activations of all the cells in real time.</p>

  <div class="controls l-page" id="figure-cells-draw-controls" style="margin-top: 36px;">
    <button onclick="document.querySelector('figure-cells-draw').clear()">Clear</button>
  </div>
  <figure-cells-draw class="l-page" mode="sorted" defaults="55,0"></figure-cells-draw>

  <hr>

  <h2>Conclusion</h2>

  <p>The black box reputation of machine learning models is well deserved, but we believe part of that reputation has been born from the programming context into which they have been locked. The experience of having an easily inspectable model available in the same programming context as the interactive visualization environment (here, javascript) proved to be very productive for prototyping and exploring new ideas for this post.</p>

  <p>As we are able to move them more and more into the same programming context that user interface work is done, we believe we will see richer modes of human-ai interactions flourish. This could have a marked impact on debugging and building models, for sure, but also in how the models are used. Machine learning research typically seeks to mimic and substitute humans, and increasingly it’s able to. What seems less explored is using machine learning to augment humans. This sort of complicated human-machine interaction is best explored when the full capabilities of the model are available in the user interface context.</p>

</dt-article>

<dt-appendix>

  <h3>Acknowledgments</h3>

  <p>We are grateful for the comments of Fernanda Viegas, Martin Wattenberg, and Daniel Smilkov.

  <p>This work was made possible by the support of the <a href="https://research.google.com/teams/brain/">Google Brain</a> team.

  <h3>Author Contributions</h3>

  <p>Shan Carter wrote the article and created the interactive experiments in the first section. David Ha created the handwriting model and ported it to Javascript. Ian Johnson created the final diagrams exploring activations. Chris Olah provided guidance and core ideas for the diagrams and edited the article.</p>

</dt-appendix>

<script type="text/bibliography">
@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013},
  url={https://arxiv.org/pdf/1308.0850v5.pdf}
}

@misc{ha2016handwriting,
 title={Handwriting Generation Demo in TensorFlow},
 author={Ha, David},
 date={2016},
 url={http://blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow/}
}

@article{maaten2008visualizing,
  title={Visualizing data using t-SNE},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008},
  url={http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf}
}

@misc{olah2015understanding,
 title={Understanding LSTM Networks},
 author={Olah, Christopher},
 date={2015},
 url={http://colah.github.io/posts/2015-08-Understanding-LSTMs/}
}

</script>
